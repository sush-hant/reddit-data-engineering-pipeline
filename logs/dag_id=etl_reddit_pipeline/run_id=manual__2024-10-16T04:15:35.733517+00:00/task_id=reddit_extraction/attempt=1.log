[2024-10-16T04:15:38.083+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-10-16T04:15:38.127+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-10-16T04:15:35.733517+00:00 [queued]>
[2024-10-16T04:15:38.131+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-10-16T04:15:35.733517+00:00 [queued]>
[2024-10-16T04:15:38.131+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2024-10-16T04:15:38.139+0000] {taskinstance.py:2888} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-10-16 04:15:35.733517+00:00
[2024-10-16T04:15:38.143+0000] {standard_task_runner.py:72} INFO - Started process 49 to run task
[2024-10-16T04:15:38.148+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-10-16T04:15:35.733517+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpxg9kzzfy']
[2024-10-16T04:15:38.149+0000] {standard_task_runner.py:105} INFO - Job 40: Subtask reddit_extraction
[2024-10-16T04:15:38.281+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-10-16T04:15:35.733517+00:00 [running]> on host b9aa631950cc
[2024-10-16T04:15:38.455+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Sushant' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-10-16T04:15:35.733517+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-10-16T04:15:35.733517+00:00'
[2024-10-16T04:15:38.457+0000] {taskinstance.py:731} INFO - ::endgroup::
[2024-10-16T04:15:38.612+0000] {base.py:84} INFO - Retrieving connection 'reddit_api'
[2024-10-16T04:15:38.811+0000] {logging_mixin.py:190} INFO - connected to reddit!
[2024-10-16T04:15:41.000+0000] {logging_mixin.py:190} INFO - [{'id': '1g47jf4', 'title': 'Data engineering market rebounding? LinkedIn shows signs of pickup; anyone else ?', 'score': 108, 'num_comments': 73, 'author': Redditor(name='TransportationOk2403'), 'created_utc': 1728998391.0, 'url': 'https://i.redd.it/sgomu9ul7xud1.png', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g3zquw', 'title': 'Introducing the dbt Column Lineage Extractor: A Lightweight Tool for dbt Column Lineage', 'score': 56, 'num_comments': 8, 'author': Redditor(name='Nice-Pattern-3287'), 'created_utc': 1728966881.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g3zquw/introducing_the_dbt_column_lineage_extractor_a/', 'over_18': False, 'edited': 1728970210.0, 'spoiler': False, 'stickied': False}, {'id': '1g44ju1', 'title': 'Company wants to set up a Data warehouse - I am a Analyst not an Engineer', 'score': 37, 'num_comments': 34, 'author': Redditor(name='Newosan'), 'created_utc': 1728988351.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g44ju1/company_wants_to_set_up_a_data_warehouse_i_am_a/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g43c4w', 'title': 'Help a junior data engineer left on his own', 'score': 33, 'num_comments': 10, 'author': Redditor(name='OpenProfessional3401'), 'created_utc': 1728982871.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g43c4w/help_a_junior_data_engineer_left_on_his_own/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4mkz4', 'title': 'Some advice for job seekers from someone on the other side', 'score': 33, 'num_comments': 1, 'author': Redditor(name='molodyets'), 'created_utc': 1729037958.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4mkz4/some_advice_for_job_seekers_from_someone_on_the/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4er7o', 'title': "Limitations of dbt's microbatch incremental models", 'score': 33, 'num_comments': 19, 'author': Redditor(name='captaintobs'), 'created_utc': 1729017028.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4er7o/limitations_of_dbts_microbatch_incremental_models/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g49ph4', 'title': 'Let’s talk about open compute + a workshop exploring it', 'score': 23, 'num_comments': 0, 'author': Redditor(name='Thinker_Assignment'), 'created_utc': 1729004318.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g49ph4/lets_talk_about_open_compute_a_workshop_exploring/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g43nel', 'title': 'snowflake & Talend ', 'score': 10, 'num_comments': 7, 'author': Redditor(name='EmbarrassedDance498'), 'created_utc': 1728984385.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g43nel/snowflake_talend/', 'over_18': False, 'edited': 1728986758.0, 'spoiler': False, 'stickied': False}, {'id': '1g42loo', 'title': 'UI app to interact with click house self hosted CH-UI ', 'score': 5, 'num_comments': 0, 'author': Redditor(name='CacsAntibis'), 'created_utc': 1728979229.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g42loo/ui_app_to_interact_with_click_house_self_hosted/', 'over_18': False, 'edited': 1728979464.0, 'spoiler': False, 'stickied': False}, {'id': '1g4n4zf', 'title': 'I need help copying a large volume of data to a SQL database.', 'score': 4, 'num_comments': 10, 'author': Redditor(name='stock_daddy'), 'created_utc': 1729039609.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4n4zf/i_need_help_copying_a_large_volume_of_data_to_a/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4lm6o', 'title': 'Combining Source Data at the Final Layer', 'score': 3, 'num_comments': 2, 'author': Redditor(name='Soundeth'), 'created_utc': 1729035098.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4lm6o/combining_source_data_at_the_final_layer/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4co8p', 'title': 'What kind of data do you folks work on? ', 'score': 5, 'num_comments': 6, 'author': Redditor(name='selfbetrue_'), 'created_utc': 1729011775.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4co8p/what_kind_of_data_do_you_folks_work_on/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4cifq', 'title': 'I built a tool to deploy local Jupyter notebooks to cloud compute (feedback appreciated!)', 'score': 5, 'num_comments': 1, 'author': Redditor(name='tmychow'), 'created_utc': 1729011392.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4cifq/i_built_a_tool_to_deploy_local_jupyter_notebooks/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g49pz6', 'title': 'Software Engineering Fundamentals.', 'score': 5, 'num_comments': 2, 'author': Redditor(name='Effective_Bluebird19'), 'created_utc': 1729004356.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g49pz6/software_engineering_fundamentals/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4l3wz', 'title': 'Looking for a Code-Centric Alternative to Azure Data Factory for Remote Data Extraction', 'score': 3, 'num_comments': 0, 'author': Redditor(name='aussiefirebug'), 'created_utc': 1729033627.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4l3wz/looking_for_a_codecentric_alternative_to_azure/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4kjx6', 'title': 'Tools for large datasets of tabular data', 'score': 3, 'num_comments': 2, 'author': Redditor(name='Annual_Elderberry541'), 'created_utc': 1729032075.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4kjx6/tools_for_large_datasets_of_tabular_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4evnf', 'title': 'Why do I need Meltano?', 'score': 1, 'num_comments': 5, 'author': Redditor(name='Temporary_Basil_7801'), 'created_utc': 1729017340.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4evnf/why_do_i_need_meltano/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g42srw', 'title': 'How reliable do you think are the statistics of this DB ranking website?', 'score': 3, 'num_comments': 2, 'author': Redditor(name='Leweth'), 'created_utc': 1728980190.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g42srw/how_reliable_do_you_think_are_the_statistics_of/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4im00', 'title': 'Books or Resources on System Design, Architecture, building Data-y business ‘stuff’?', 'score': 2, 'num_comments': 1, 'author': Redditor(name='Visible_Extension291'), 'created_utc': 1729026814.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4im00/books_or_resources_on_system_design_architecture/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4c3tv', 'title': 'Mini Data Engineering Project: Monitor DAGs and Tasks in Airflow with Airbyte, Snowflake, and Superset', 'score': 1, 'num_comments': 0, 'author': Redditor(name='marclamberti'), 'created_utc': 1729010375.0, 'url': 'https://youtu.be/x7oRfH4ig54', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g44cmv', 'title': 'Starting US based consultancy - insurance questions', 'score': 2, 'num_comments': 0, 'author': Redditor(name='xephadoodle'), 'created_utc': 1728987521.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g44cmv/starting_us_based_consultancy_insurance_questions/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g42f5j', 'title': 'Code security', 'score': 2, 'num_comments': 5, 'author': Redditor(name='kerokero134340'), 'created_utc': 1728978339.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g42f5j/code_security/', 'over_18': False, 'edited': 1728999282.0, 'spoiler': False, 'stickied': False}, {'id': '1g4hbgo', 'title': 'AWS services vs vendor solutions?', 'score': 1, 'num_comments': 0, 'author': Redditor(name='yingjunwu'), 'created_utc': 1729023532.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4hbgo/aws_services_vs_vendor_solutions/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4elbs', 'title': 'How to go about testing a new Hadoop cluster', 'score': 1, 'num_comments': 0, 'author': Redditor(name='Agile-Flower420'), 'created_utc': 1729016615.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4elbs/how_to_go_about_testing_a_new_hadoop_cluster/', 'over_18': False, 'edited': 1729016832.0, 'spoiler': False, 'stickied': False}, {'id': '1g43xrm', 'title': 'Looking for advice, manager who wants to get back to a technical role.', 'score': 1, 'num_comments': 1, 'author': Redditor(name='Humble_Ostrich_4610'), 'created_utc': 1728985743.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g43xrm/looking_for_advice_manager_who_wants_to_get_back/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4ghd3', 'title': 'Help with business-driven ', 'score': 0, 'num_comments': 1, 'author': Redditor(name='Rodnarokk'), 'created_utc': 1729021404.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4ghd3/help_with_businessdriven/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4fc74', 'title': 'Working in data with a MS in Marketing ', 'score': 0, 'num_comments': 3, 'author': Redditor(name='Foreign_Analyst'), 'created_utc': 1729018498.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4fc74/working_in_data_with_a_ms_in_marketing/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4da02', 'title': 'SQL Server: Best Approach for Copying Large Data (10M to 100M Rows) Between Instances?', 'score': 0, 'num_comments': 9, 'author': Redditor(name='GreyArea1985'), 'created_utc': 1729013285.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4da02/sql_server_best_approach_for_copying_large_data/', 'over_18': False, 'edited': 1729015704.0, 'spoiler': False, 'stickied': False}, {'id': '1g4c533', 'title': 'GCP Certification', 'score': 0, 'num_comments': 0, 'author': Redditor(name='Traditional-Pen9365'), 'created_utc': 1729010461.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4c533/gcp_certification/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g47c99', 'title': 'Need Career Advice ', 'score': 0, 'num_comments': 0, 'author': Redditor(name='kiran-187'), 'created_utc': 1728997810.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g47c99/need_career_advice/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4g9q2', 'title': 'I’m do I have for title role now?', 'score': 0, 'num_comments': 1, 'author': Redditor(name='AdPrimary4289'), 'created_utc': 1729020859.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4g9q2/im_do_i_have_for_title_role_now/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1g4h4y6', 'title': 'What tool should you learn to be señor ingeniero de datos?', 'score': 0, 'num_comments': 33, 'author': Redditor(name='Temporary_Basil_7801'), 'created_utc': 1729023069.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1g4h4y6/what_tool_should_you_learn_to_be_señor_ingeniero/', 'over_18': False, 'edited': 1729028584.0, 'spoiler': False, 'stickied': False}]
[2024-10-16T04:15:41.006+0000] {python.py:240} INFO - Done. Returned value was: None
[2024-10-16T04:15:41.030+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-10-16T04:15:41.031+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, run_id=manual__2024-10-16T04:15:35.733517+00:00, execution_date=20241016T041535, start_date=20241016T041538, end_date=20241016T041541
[2024-10-16T04:15:41.097+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2024-10-16T04:15:41.150+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-10-16T04:15:41.153+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
